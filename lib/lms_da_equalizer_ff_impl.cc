/* -*- c++ -*- */
/*
 * Copyright (C) 2016  Andy Walls <awalls.cx18@gmail.com>
 *
 * This file was automatically generated by gr_modtool from GNU Radio
 *
 * This file was automatically generated from a template incorporating
 * data input by Andy Walls.
 * See http://www.gnu.org/licenses/gpl-faq.en.html#GPLOutput .
 */

#ifdef HAVE_CONFIG_H
#include "config.h"
#endif

#include <gnuradio/io_signature.h>
#include "lms_da_equalizer_ff_impl.h"
#include <volk/volk.h>

namespace gr {
  namespace nwr {

    lms_da_equalizer_ff::sptr
    lms_da_equalizer_ff::make(const std::vector<float> &training_samples,
                              const std::string &sync_tag,
                              unsigned int num_taps,
                              float mu)
    {
      return gnuradio::get_initial_sptr
        (new lms_da_equalizer_ff_impl(training_samples,
                                      sync_tag,
                                      num_taps,
                                      mu));
    }

    lms_da_equalizer_ff_impl::lms_da_equalizer_ff_impl(
                                     const std::vector<float> &training_samples,
                                     const std::string &sync_tag,
                                     unsigned int num_taps,
                                     float mu)
      : gr::sync_block("lms_da_equalizer_ff",
              gr::io_signature::make(1, 1, sizeof(float)),
              gr::io_signature::make(1, 1, sizeof(float))),
        fir_filter_fff(1, std::vector<float>(num_taps, 0.0f)),
        d_sync_tag_key(pmt::intern(sync_tag)),
        d_new_taps(num_taps, 0.0f),
        d_updated(false),
        d_training_samples(training_samples),
        d_error(0.0f)
    {
        const int alignment_multiple = volk_get_alignment() / sizeof(float);
        set_alignment(std::max(1, alignment_multiple));

        set_gain(mu);

        if (num_taps > 0)
            d_new_taps[0] = 1.0f;
        fir_filter_fff::set_taps(d_new_taps);
        set_history(fir_filter_fff::ntaps());
        declare_sample_delay(0, (fir_filter_fff::ntaps() - 1)/2);
    }

    lms_da_equalizer_ff_impl::~lms_da_equalizer_ff_impl()
    {
    }

    void
    lms_da_equalizer_ff_impl::set_taps(const std::vector<float> &taps)
    {
        // FIXME check on tap reversal
        d_new_taps = taps;
        d_updated = true;
    }

    std::vector<float>
    lms_da_equalizer_ff_impl::taps() const
    {
        // FIXME check on tap reversal
        return fir_filter_fff::taps();
    }

    void
    lms_da_equalizer_ff_impl::reinit_taps(void)
    {
        std::vector<float> initial_taps(fir_filter_fff::ntaps(), 0.0f);

        if (initial_taps.size() > 0)
            initial_taps[0] = 1.0;
        fir_filter_fff::set_taps(initial_taps);
    }

    float
    lms_da_equalizer_ff_impl::a_priori_error(unsigned int i, float y)
    {
        return d_training_samples[i] - y;
    }

    void
    lms_da_equalizer_ff_impl::update_tap(float &tap, const float x)
    {
        tap += d_mu * x * d_error;
    }

    void
    lms_da_equalizer_ff_impl::filter_no_adapt(float *out, const float *in,
                                              unsigned int len)
    {
        fir_filter_fff::filterN(out, in, static_cast<unsigned long>(len));
    }

    void
    lms_da_equalizer_ff_impl::filter_and_adapt(float *out, const float *in,
                                               unsigned int len)
    {
        unsigned int i, j;
        unsigned int n = fir_filter_fff::ntaps();

        for (i = 0; i < len; i++) {
            // Filter the next sample
            out[i] = fir_filter_fff::filter(&in[i]);

            // Compute the a-priori error from the expected signal
            d_error = a_priori_error(i, out[i]);

            // Adapt the equalization filter taps based on the error
            for (j = 0; j < n; j++) {
                // Update tap locally from d_error
                // N.B. this relies on the fir_filter_fff object's
                // d_taps being stored in reverse order.
                update_tap(d_taps[j], in[i+j]);

                // Update aligned taps in fir_filter_fff object
                fir_filter_fff::update_tap(d_taps[j], j);
            }
        }
    }

    bool
    lms_da_equalizer_ff_impl::p_tag_compare(const tag_t &a, const tag_t &b)
    {
        return (pmt::to_double(a.value) < pmt::to_double(b.value));
    }


    void
    lms_da_equalizer_ff_impl::prune_sync_tags(std::vector<tag_t> p_tags)
    {
        unsigned int training_len = d_training_samples.size();
        uint64_t ofirst;
        std::vector<tag_t>::iterator p;
        std::vector<tag_t> cluster;
        std::vector<tag_t> output;

        std::sort(p_tags.begin(), p_tags.end(), tag_t::offset_compare);

        // Sync sequence correlation tags will cluster together near the
        // start of a sync sequence so ditch all but the maximum in each 
        // cluster. We assume the lower valued ones are false correlations
        // due to the correlator threshold setting being too low.
        output.clear();
        p = p_tags.begin();
        while (p != p_tags.end()) {
            // This sync tag starts a new cluster
            cluster.clear();
            ofirst = p->offset;

            // Add nearby sync tags to the cluster
            do {
                cluster.push_back(*p);
                p++;
            } while (p != p_tags.end() and
                     p->offset < (ofirst + training_len));

            // Select the sync tag with the maximum correlation value
            // as the winner.
            output.push_back(*std::max_element(cluster.begin(),
                                               cluster.end(),
                                      lms_da_equalizer_ff_impl::p_tag_compare));
        }

        p_tags = output;
    }


    int
    lms_da_equalizer_ff_impl::work(int noutput_items,
        gr_vector_const_void_star &input_items,
        gr_vector_void_star &output_items)
    {
        const float *in = (const float *) input_items[0];
        float *out = (float *) output_items[0];

        // If the user forces the equalizer taps, then change them.
        // Since we will reinit the taps at the next sync sequence,
        // the particular user taps values don't matter much.
        // This is really only useful for changing the length of the
        // equalization filter.
        if (d_updated) {
            fir_filter_fff::set_taps(d_new_taps);
            set_history(fir_filter_fff::ntaps());
            declare_sample_delay(0, (fir_filter_fff::ntaps() - 1)/2);
            d_updated = false;
            return 0; // history requirement may have changed
        }

        uint64_t soffset = nitems_read(0);

        // Get all the sync tags in offset order
        std::vector<tag_t> p_tags;
        std::vector<tag_t>::iterator p;
        get_tags_in_range(p_tags,
                          0, soffset, soffset + noutput_items, d_sync_tag_key);

        prune_sync_tags(p_tags);

        unsigned int training_len = d_training_samples.size();

        int idx = 0;
        uint64_t w_start = soffset;
        uint64_t w_len;

        // We work under the assumption that we will never start mid sync seq.

        for (p = p_tags.begin(); p != p_tags.end(); p++) {
            if (p->offset < w_start) {
                // Hmm. Somehow after pruning we still had multiple
                // sync tag markers within 1 sync sequence length.
                // We already performed filtering and data-aided adaptation
                // based on the first marker, so ditch this one.
                continue;
            }

            // Filter without and adaptation
            w_len = p->offset - w_start;
            filter_no_adapt(&out[idx], &in[idx], w_len);
            idx += w_len;
            w_start += w_len;

            // If not enough items left to perform Data-Aided adapation,
            // then bail-out, so we never come into work() mid sync sequence. 
            if (idx + training_len >= noutput_items)
                return idx;

            // Reset equalization filter and filter and perform
            // Data-Aided adaptation using the training samples 
            w_len = training_len;
            reinit_taps();
            filter_and_adapt(&out[idx], &in[idx], w_len);
            idx += w_len;
            w_start += w_len;
        }

        // Filter without and adaptation
        w_len = (soffset + noutput_items) - w_start;
        filter_no_adapt(&out[idx], &in[idx], w_len);
        idx += w_len;
        w_start += w_len;
        return idx;
    }

  } /* namespace nwr */
} /* namespace gr */

